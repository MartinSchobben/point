#' Read raw ion count data
#'
#' \code{read_IC()} is designed to obtain the numerical data associated with ion
#' counts.
#' \code{read_meta()} can be used to specifically retrieve the metadate
#' associated with ion count data analysis, thereby loading specifications
#' related to the optics, the primary and secondary ion beams, and the mass
#' spectrometer.
#'
#' Ion count data consists of time-incremented integer values. These functions
#' are currently only supported for data generated by a NanoSIMS50L. Raw ion
#' count data and accompanying is extracted and collated into a single tibble
#' from text files with the extensions \emph{.is_txt} \emph{.chk_is} and
#' \emph{.stat}, respectively. These files can be found in the directories
#' associated with the SIMS measurements.
#'
#' @param directory A path or connection to a directory containing raw ion count
#' data txt  files.
#' @param meta Logical indicating whether to include metadata.
#' @param hide Logical indicating whether metadata is included as columns
#'  \code{FALSE} or as an attribute of the tibble \code{TRUE}.
#'
#'
#' @return A \code{tibble::\link[tibble:tibble]{tibble}} containing raw ion
#' count data and metadata.
#' @export
#' @examples
#' # Use point_example() to access the examples bundled with this package
#'
#' read_IC(point_example("2018-01-19-GLENDON"))
read_IC <- function(directory, meta = TRUE, hide = TRUE){

  # List files
  ls_IC <- read_validator(directory, "is_txt")[["ion"]]

  # Collecting measurement data
  tb_IC <- vroom::vroom(
    ls_IC,
    comment = "B",
    delim = "\t",
    skip = 1,
    col_types = "-dd",
    col_select = c(file.nm, t.nm = X, N.rw = Y),
    na = c("X", "Y"),
    id = "file.nm",
    .name_repair = "minimal"
    ) %>%
    tidyr::drop_na() %>%
    group_by(file.nm) %>%
    mutate(
      # simplify file name
      file.nm = recode(file.nm, !!! set_names(names(ls_IC), ls_IC)),
      # detector number based on position in file
      num.mt = ntile(n = n() / n_distinct(t.nm))
      ) %>%
    ungroup()

  point_nms <- filter(point::names_cameca, extension == ".is_txt", use == "meta")
  tb_meta <- point_lines(ls_IC, pattern = "B", sep = "\\=") %>%
    # meta data names
    rename(set_names(point_nms$cameca, nm = point_nms$point)) %>%
    # detector numbering
    group_by(file.nm) %>%
    mutate(
      num.mt = row_number(),
      # species names
      species.nm = stringr::str_extract(mass.mt, "(?<=\\().+?(?=\\))")
      ) %>%
    ungroup()

  tb_rw <- left_join(tb_IC, tb_meta, by = c("file.nm", "num.mt"))
  # hide meta data
  if (hide) tb_rw <- fold(tb_rw, type = ".mt")
  tb_rw
  }

h <- function(x){
  # Collecting metadata (stat file)
  if (meta) {
    # Check validity of directory for meta data extraction
    read_validator(directory)
    tb_meta <- read_meta(directory)
  }

  if (meta) {
    # vector with species names
    vc_species <- set_names(
      unique(tb_meta$species.nm),
      nm = 1:length(unique(tb_meta$species.nm))
      )

    # combine meta and ion count data
    tb_rw <- group_by(tb_rw, .data$file.nm) %>%
      mutate(
        species.nm = ntile(n = length(unique(tb_meta$species.nm))),
        species.nm = recode(.data$species.nm, !!! vc_species)
        ) %>%
      ungroup() %>%
      left_join(tb_meta, by = c("file.nm", "species.nm")) %>%
      # add block numbers
      group_by(.data$file.nm, .data$species.nm) %>%
      mutate(bl.nm = ntile(n = .data$bl_num.mt)) %>%
      ungroup()


    if (hide) tb_rw <- fold(tb_rw, type = ".mt")
    tb_rw
  }
  tb_rw
}
#' @rdname read_IC
#'
#' @export
read_meta <- function(directory){

  # Check validity of directory
  ls_files <- read_validator(directory)

#-------------------------------------------------------------------------------
# PHD
#-------------------------------------------------------------------------------
  # Number of PHD measurements
  PHD_n <- row_scanner(directory, ls_files[["optic"]], "PHDc(?=\\(Mass)")

  # List of function arguments for PHD
  ls_PHD <- lst(a = ls_files[["optic"]], b = PHD_n, c = lapply(.data$b, length))

  # Apply PHD reading function to list of arguments
  tb_PHD <- purrr::pmap_dfr(
    ls_PHD,
    PHD_fun,
    directory = directory,
    .id = "file.nm"
    )

#-------------------------------------------------------------------------------
# Ions and MS setup metadata
#-------------------------------------------------------------------------------
  # Minimum of metadata rows
  min_n <- row_scanner(directory, ls_files[["stat"]], "#") %>%
    purrr::map_dbl(1)

  # Maximum of metadata rows
  max_n <- row_scanner(directory, ls_files[["stat"]], "--") %>%
    purrr::map_dbl(1)

  # List of function arguments for meta-data function
  ls_ion <- lst(a = ls_files[["stat"]], b =  min_n, c = (max_n - 3) - .data$b)

  # Apply PHD reading function to list of arguments
  tb_ion <- purrr::pmap_dfr(
    ls_ion,
    ion_fun,
    directory = directory,
    .id = "file.nm"
    )

#-------------------------------------------------------------------------------
# Primary and secondary ion beam metadata
#-------------------------------------------------------------------------------
  tb_meas <- purrr::map2_dfr(
    ls_files[["optic"]],
    min_n - 2,
    meas_fun,
    directory = directory,
    .id = "file.nm"
    )

  # Cameca parameters
   vc_params <- set_names(point::names_cameca$cameca, point::names_cameca$point)

  # Select variables
   tb_meas <- select(tb_meas , any_of(c("file.nm", "sample.nm", vc_params))) %>%
     mutate(
      across(contains(".mt"), readr::parse_guess),
  # Add measurement number
      n.rw = .data$`bl_num.mt` * .data$`meas_bl.mt`,
  # Add electron detector type (EM or FC)
      det_type.mt = if_else("FC_start.mt" %in% colnames(.), "FC", "EM")
      )

  # Combine PHD, MS and beam metadata (make list columns of metadata)
  purrr::reduce2(
      lst(tb_ion, tb_meas, tb_PHD),
      lst(by = c("file.nm"), by = c("file.nm", "num.mt")),
      left_join
      )
  }

#' Get path to point example
#'
#' This function comes from the package `readr`, and has been modified to access
#' the bundled datatsets in directory `inst/extdata` of `point`. This
#' function make them easy to access. This function is modified from
#' \code{\link[readr:readr_example]{readr_example}} of the package
#' \code{\link[readr]{readr}}.
#'
#' @param path Name of file. If `NULL`, the example files will be listed.
#' @export
#' @examples
#' point_example()
#' point_example("2018-01-19-GLENDON")
point_example <- function(path = NULL) {
  if (is.null(path)) {
    dir(system.file("extdata", package = "point"))
  } else {
    system.file("extdata", path, package = "point", mustWork = TRUE)
  }
}

#' Check if directory is suitable for point
#'
#' This function checks whether the necessary files for the `point` read
#' functions are included in the directory.
#'
#' @param directory A path or connection to a directory containing raw ion count
#' data files.
#' @param types Regular expression for the required file extensions. Default
#' searches for files ending with .is_txt, .chk_is, and .stat
#'
#' @return A logical indicating whether the directory is suitable for `point`
#' @export
#' @examples
#' ICdir_chk(point_example("2018-01-19-GLENDON"))
ICdir_chk <-function(directory, types = c("is_txt", "chk_is", "stat")){
  # types <- paste0(".", types)
  # check if type is valid
  sys_types <- c(ion = "is_txt", optic = "chk_is", stat = "stat")
  if (any(types %in% sys_types)) {
    types <- sys_types[sys_types %in% types]
  } else {
    stop("Unknown extension.", call. = FALSE)
  }
  # directory name if also file name
  dir_nm <- stringr::str_extract(
    directory,
    stringr::str_c("(?<=", dirname(directory), "/)(.)+")
    )
  ls_files <- fs::dir_ls(directory)%>%
    purrr::keep(stringr::str_detect(., pattern = dir_nm))
  ls_names <- unique(fs::path_ext_remove(fs::path_file(ls_files))) %>%
    purrr::keep(stringr::str_detect(., pattern = "(_[[:digit:]]+_[[:digit:]]+)$"))
  ls_types <- purrr::cross(list(directory, ls_names, ext = types)) %>%
    purrr::map_chr(purrr::lift(fs::path)) %>%
    set_names(nm = rep(ls_names, n_distinct(types)))

  if (length(ls_types > 0) & all(ls_types %in% ls_files)) {
    # makes grouped list
    split(ls_types, rep(names(types), each = n_distinct(ls_names)))
  } else {
    FALSE
  }
}

#' Access and hide IC metadata
#'
#' \code{unfold()} helps unpack metadata associated with ion count
#' data loaded with \code{read_IC()}. \code{fold()} does the opposite an hides
#' the metadata as attribute of the tibble.
#'
#' @param df A tibble containing ion count data along any point of the point-
#' workflow
#' @param type A character string identifying the metadata (default:
#' \code{"metadata"})
#' @param merge Logical dictating whether metadata is joined to the tibble or
#' returned as a separate file.
#' @param meta Additional tibble containing the metadata for storage along the
#' main IC data.
#'
#' @return A tibble with metadata as an attribute, columns or as a seperate
#' tibble.
#' @export
#' @examples
#' tb_rw <- read_IC(point_example("2018-01-19-GLENDON"), hide = TRUE)
#'
#' # Unfold metadata
#' unfold(tb_rw, merge = FALSE)
unfold <- function(df, type = "metadata", merge = TRUE) {
  # no attribute of name type return unchanged data
  if (is.null(attr(df, type))) {
    warning("Attribute unavailable.", call. = FALSE)
    return(df)
  }
  meta <- attr(df, type)
  vars <- select(meta, ends_with(".nm")) %>%
    colnames()
  vars <- vars[which(vars %in% colnames(df))]
  if (merge) return(left_join(df, meta, by = vars)) else return(meta)
}
#' @rdname unfold
#'
#' @export
fold <- function(df, type, meta = NULL) {

  vc_type <- c(`metadata` = ".mt", `rawdata` = ".rw", `modeldata` = ".ml")
  vc_type <- vc_type[vc_type %in% type]

  if (is.null(meta)){
    tb <- select(df, -c(ends_with(type)))
    ls_tb <- purrr::map(vc_type, ~select(df, ends_with(".nm") | ends_with(.x)))
    ls_tb[[length(vc_type) + 1]] <- (tb)
  } else {
    ls_tb <- list2(metadata = meta, df)
  }
  purrr::reduce2(rev(ls_tb), rev(names(vc_type)), write_attr)
}

#-------------------------------------------------------------------------------
# Function for testing and validation (NOT EXPORTET)
#-------------------------------------------------------------------------------
# Validation function to check for empty files or files with empty columns
read_validator <- function(directory, types = c("is_txt", "chk_is", "stat")){

  # Argument class check
  stopifnot(fs::is_dir(directory))

  # Check if directory contains files
  if (is.null(length(dir(directory)))) {
    stop("`directory` does not contain any files.", call. = FALSE)
  }
  # Check if directory contains specified file types
  if (isFALSE(ICdir_chk(directory, types))) {
    stop("`directory` does not contain required filetypes: .is_txt, .chk_is, and .stat.",
         call. = FALSE)
  } else {
    ls_files <- ICdir_chk(directory, types)
  }

  # Length check of txt files
  if ("is_txt" %in% types & any(missing_text(ls_files[["ion"]]) == 0)) {
   good <- missing_text(directory, ls_files[["ion"]]) > 0
   ls_files[["ion"]] <- ls_files[["ion"]][good]
   warning("Empty txt file removed.")
  } else {
  return(ls_files)
  }
}

# Function for obtaining xyz coordinates on analytical substrate
str_loc <- function(loc) {
  loc %>%
    stringr::str_split("=+", simplify = TRUE) %>%
    stringr::str_subset("[:digit:]") %>%
    sapply(readr::parse_number) %>%
    set_names(nm = c("x.mt", "y.mt", "z.mt"))
}

# Function to recreate count blocks
fun_bl<- function(x, y) {
  seq <- rep(1: unique(x), each = unique(y))
  n <- row_number()
  seq[n]
}

# Function for PHD data reading
PHD_fun <- function(directory, a, b, c) {
  readr::read_table2(
    paste0(directory, "/", a),
    col_names = c("num.mt", "mean_PHD.mt", "SD_PHD.mt", "EMHV.mt"),
    col_types = "-cddd",
    na = c(mapply(strrep,"X", 1:10, USE.NAMES = FALSE), "1.#R"),
    skip = b[1] - 1,
    n_max = c
    ) %>%
    mutate(num.mt = readr::parse_number(.data$num.mt))
}

# Function for mass spec data reading
ion_fun <- function(directory, a, b, c) {
  readr::read_table(
    paste0(directory, "/", a),
    skip = b,
    n_max = c,
    col_names = c("num.mt", "species.nm", "mass.mt", "det.mt", "tc.mt",
                  "bfield.mt", "rad.mt"),
    col_types = "icdcddd---"
    )
}

# Function for optics reading
meas_fun <- function(directory, a , b) {

  NA_aliases <- c("N/A", "none", "None") %>%
    set_names(rep(NA_character_, length(.)), nm = .)

  tb_meas <- readr::read_table(
    paste0(directory, "/", a),
    col_names = "var",
    col_types = "c",
    n_max = b,
    skip_empty_rows = FALSE
    ) %>%
    tidyr::drop_na()

  name <- stringr::str_trim(stringr::str_split(pull(tb_meas, "var")[1],"\\:")[[1]][2])
  date <- pull(tb_meas, "var")[2] %>% stringr::str_trim()
  loc <- pull(tb_meas, "var")[3]  %>% stringr::str_trim()

  tb_meas <- tidyr::separate_rows(
    slice(tb_meas, 4:nrow(tb_meas)),
    .data$var,
    sep = "(/(?=[[:blank:]])) | ="
    ) %>%
    tidyr::separate(
      .data$var,
      into = c("var", "value"),
      sep =":(?!\\\\)",
      extra = "merge"
    ) %>%
    mutate(across(everything(), stringr::str_trim)) %>%
    distinct(.data$var, .keep_all = TRUE) %>%
    mutate(
    # Find missing meta
      value = recode(.data$value, !!! NA_aliases),
      # Remove units behind numeric
      value = stringr::str_replace(
        .data$value,
        "(?<=[:digit:]|[:blank:])(pA|um|%)|Det1=",
        ""
        )
      ) %>%
    tidyr::pivot_wider(
      names_from = .data$var,
      values_from = .data$value
      ) %>%
    # Separate extraction of date, location and name
    mutate(
      sample.nm = name,
      date.mt = as.POSIXct(date, format = c("%d.%m.%y  %H:%M")),
      !!!str_loc(loc)
      ) %>%
    mutate(across(everything(), stringr::str_trim))
}

# Row scanner determine number of rows
row_scanner <- function(ls, reg_expr, return_line = FALSE) {
  lines <- vroom::vroom_lines(ls)
  pos_line <- stringr::str_which(lines, reg_expr)
  ext_line <- lines[pos_line]
  # Are these lines identical ?
  if (isTRUE(return_line)) {
    if (length(unique(ext_line)) > 1) warning("Column names are not equal.", call. = FALSE)
    list(pos_line, unique(ext_line))
  } else {
    pos_line
  }
}

# File validator. Empty text files
missing_text <- function(files) {
  purrr::map_dbl(files, ~length(vroom::vroom_lines(.x, n_max = 2)))
}

write_attr <- function(df1, df2, nm) {
  attr(df1, nm) <- df2
  df1
}

point_lines <- function(files, pattern = NULL, position = NULL, sep = NULL, delim = ":") {
  # names files
  file_nms <- names(files)
  # load all lines
  files <- vroom::vroom_lines(files)

  # filter lines
  if (!is.null(position)) {
    files <- files[position]
  } else if (!is.null(pattern)) {
    files <- stringr::str_subset(files, pattern = stringr::str_c("\\Q", pattern, "\\E", collapse = "|"))
  }

  # update names if multiple rows are extracted per file
  if (length(files) > length(file_nms)) file_nms <- rep(file_nms, each = length(files) %/% length(file_nms))

  # extract column names with regex
  col_nms <- stringr::str_extract_all(files, paste0("(?<=(^|\\", delim, "))(.)+?(?=", sep ,")")) %>%
    purrr::flatten_chr() %>%
    stringr::str_trim() %>%
    unique()
  # regex column names
  remove_reg <- stringr::str_c("(\\Q", col_nms, "\\E\\s*", sep, ")", collapse = "|")
  # extract column names regex from outpur to obtain values
  vals <- stringr::str_remove_all(files, paste0(remove_reg, "|\\s"))
  # create appropriate value separators
  separators <- rep(c(rep(delim, length(pattern) - 1), "\n"), length(files) / length(pattern))
  vals <- stringr::str_c(vals, separators, collapse = "")
  vroom::vroom(I(vals), delim = delim, col_names = col_nms, show_col_types = FALSE) %>%
    tibble::add_column(file.nm = file_nms, .before = col_nms[1])
  }

