#' Read raw ion count data
#'
#' \code{read_IC()} is designed to obtain the numerical data associated with ion
#' counts.
#' \code{read_meta()} can be used to specifically retrieve the metadate
#' associated with ion count data analysis, thereby loading specifications
#' related to the optics, the primary and secondary ion beams, and the mass
#' spectrometer.
#'
#' Ion count data consists of time-incremented integer values. These functions
#' are currently only supported for data generated by a NanoSIMS50L. Raw ion
#' count data and accompanying is extracted and collated into a single tibble
#' from text files with the extensions \emph{.is_txt} \emph{.chk_is} and
#' \emph{.stat},respectively. These files can be found in the directories
#' associated with the SIMS measurements.
#'
#' @param directory A path or connection to a directory containing raw ion count
#' data txt  files.
#' @param meta Logical indicating whether to include metadata
#' @param hide Logical indicating whether metadata is included as columns
#'  \code{FALSE} or as an attribute of the tibble \code{TRUE}.
#'
#'
#' @return A \code{\link[tibble:tibble]{tibble}} containing raw ion count data
#' and metadata
#' @export
#' @examples
#' # Use point_example() to access the examples bundled with this package
#'
#' read_IC(point_example("2018-01-19-GLENDON"))
read_IC <- function(directory, meta = TRUE, hide = TRUE){

# List files
  ls_IC <- read_names(directory, "is_txt")
  n_max <- Inf

# Collecting metadata (stat file)
  if (meta) {
    tb_meta <- read_meta(directory)
# Check validity of directory
    ls_IC <- read_validator(directory)[[1]]
    n_max <- group_by(tb_meta, file.nm) %>%
      summarise(n = sum(n.rw)) %>%
      pull(n) + length(unique(tb_meta$species.nm)) + 1
    }

# Collecting measurement data
  tb_rw <- purrr::map2_dfr(
    ls_IC,
    n_max,
    ~read_tsv(
      paste0(directory, "/", .x),
      col_names = c("t.nm", "N.rw"),
      col_types = "-cc",
      comment = "B",
      skip = 1,
# n-max is n times number of species
      n_max = .y
       ),
    .id = "file.nm"
    ) %>%
# Remove old column headers
    filter(.data$t.nm != "X", .data$N.rw  != "Y") %>%
# Coercion to numeric values
    mutate(
      t.nm = as.numeric(.data$t.nm),
      N.rw = as.numeric(.data$N.rw)
      )


  if (meta) {
    # vector with species names
    vc_species <- set_names(
      unique(tb_meta$species.nm),
      nm = 1:length(unique(tb_meta$species.nm))
      )

    # combine meta and ion count data
    tb_rw <- group_by(tb_rw, .data$file.nm) %>%
      mutate(
        species.nm = ntile(n = length(unique(tb_meta$species.nm))),
        species.nm = recode(.data$species.nm, !!! vc_species)
        ) %>%
      ungroup() %>%
      left_join(tb_meta, by = c("file.nm", "species.nm")) %>%
      # add block numbers
      group_by(.data$file.nm, .data$species.nm) %>%
      mutate(bl.nm = ntile(n = .data$bl_num.mt)) %>%
      ungroup()


    if (hide) tb_rw <- fold(tb_rw, type = ".mt")

    # # Compare length consistency to gauge failures in measurement # reconsider this
    # if (length(compare_length(tb_rw)) > 0) {
    #   warning("Inconsistency in the length of one ore more analyses.
    #           Use the function `compare_length()` to compare IC and meta data.")
    # }

    return(tb_rw)
  }
  return(tb_rw)
}

#' @rdname read_IC
#'
#' @export
read_meta <- function(directory){

# Check validity of directory
  ls_files <- read_validator(directory)

#-------------------------------------------------------------------------------
# PHD
#-------------------------------------------------------------------------------
# Number of PHD measurements
  PHD_n <- row_scanner(directory, ls_files[["optic"]], "PHDc(?=\\(Mass)")

# List of function arguments for PHD
  ls_PHD <- lst(
    a = ls_files[["optic"]],
    b = PHD_n,
    c = lapply(.data$b, length)
    )

# Apply PHD reading function to list of arguments
  tb_PHD <- purrr::pmap_dfr(
    ls_PHD,
    PHD_fun,
    directory = directory,
    .id = "file.nm"
    )

#-------------------------------------------------------------------------------
# Ions and MS setup metadata
#-------------------------------------------------------------------------------
# Minimum of metadata rows
   min_n <- row_scanner(directory, ls_files[["stat"]], "#") %>%
    purrr::map_dbl(., 1)

# Maximum of metadata rows
  max_n <- row_scanner(directory, ls_files[["stat"]], "--") %>%
    purrr::map_dbl(., 1)

# List of function arguments for metadat function
  ls_ion <- lst(a = ls_files[["stat"]], b =  min_n  , c = (max_n - 3) - .data$b)

# Apply PHD reading function to list of arguments
  tb_ion <- purrr::pmap_dfr(
    ls_ion,
    ion_fun,
    directory = directory,
    .id = "file.nm"
    )

#-------------------------------------------------------------------------------
# Primary and secondary ion beam metadata
#-------------------------------------------------------------------------------
  tb_meas <- purrr::map2_dfr(
    ls_files[["optic"]],
    min_n - 2,
    meas_fun,
    directory = directory,
    .id = "file.nm"
    )

# Cameca parameters
   vc_params <- set_names(point::names_meta$cam, nm = point::names_meta$point)

# Select variables present
   vc_params <- vc_params[vc_params  %in% colnames(tb_meas)]
# Add required variables
   vc_params <- purrr::prepend(
     vc_params,
     c(
       file.nm = "file.nm",
       sample.nm = "sample.nm",
       date.mt = "date.mt",
       x.mt = "x.mt",
       y.mt = "y.mt",
       z.mt = "z.mt"
       )
     )

# Select variables
   tb_meas <- select(tb_meas , !!! vc_params) %>%
     mutate(
      across(contains(".mt"), parse_guess),
# Add measurement number
      n.rw = .data$`bl_num.mt` * .data$`meas_bl.mt`,
# Add electron detector type (EM or FC)
      det_type.mt = if_else("FC_start.mt" %in% colnames(.), "FC", "EM")
      )

# Combine PHD, MS and beam metadata (make list columns of metadata)
  purrr::reduce2(
      lst(tb_ion, tb_meas, tb_PHD),
      lst(by = c("file.nm"), by = c("file.nm", "num.mt")),
      left_join
      )
  }


#' Get path to point example
#'
#' This function comes from the package `readr`, and has been modified to access
#' the bundled datatsets in directory `inst/extdata` of `point`. This
#' function make them easy to access. This function is modified from
#' \code{\link[readr:readr_example]{readr_example}} of the package
#' \code{\link[readr]{readr}}.
#'
#' @param path Name of file. If `NULL`, the example files will be listed.
#' @export
#' @examples
#' point_example()
#' point_example("2018-01-19-GLENDON")
point_example <- function(path = NULL) {
  if (is.null(path)) {
    dir(system.file("extdata", package = "point"))
  } else {
    system.file("extdata", path, package = "point", mustWork = TRUE)
  }
}


#' Check if directory is suitable for point
#'
#' This function checks whether the necessary files for the `point` read
#' functions are included in the directory.
#'
#' @param directory A path or connection to a directory containing raw ion count
#' data files.
#' @param types Regular expression for the required file extensions. Default
#' searches for files ending with .is_txt, .chk_is, and .stat
#'
#' @return A logical indicating whether the directory is suitable for `point`
#' @export
#' @examples
#' ICdir_chk(point_example("2018-01-19-GLENDON"))
ICdir_chk <-function(directory, types = c(".is_txt", ".chk_is", ".stat")){

  purrr::map_lgl(paste0(types, "$"), ~any(str_detect(dir(directory), .x))) %>%
    all()
}

#' Access and hide IC metadata
#'
#' \code{unfold()} helps unpack metadata associated with ion count
#' data loaded with \code{read_IC()}. \code{fold()} does the opposite an hides
#' the metadata as attribute of the tibble.
#'
#' @param df A tibble containing ion count data along any point of the point-
#' workflow
#' @param type A character string identifying the metadata (default:
#' \code{"metadata"})
#' @param merge Logical dictating whether metadata is joined to the tibble or
#' returned as a seperate file.
#' @param meta Additional tibble containing the metadata for storage along the
#' main IC data.
#'
#' @return A tibble with metadata as an attribute, columns or as a sperate
#' tibble.
#' @export
#' @examples
#' tb_rw <- read_IC(point_example("2018-01-19-GLENDON"), hide = TRUE)
#'
#' # Unfold metadata
#' unfold(tb_rw, merge = FALSE)
unfold <- function(df, type = "metadata", merge = TRUE) {

  # no attr of name type return unchanged data
  if (is.null(attr(df, type))) return(df)
  meta <- attr(df, type)
  vars <- select(meta, ends_with(".nm")) %>%
    colnames()
  vars <- vars[which(vars %in% colnames(df))]

  if (merge) return(left_join(df, meta, by = vars)) else return(meta)
}
#' @rdname unfold
#'
#' @export
fold <- function(df, type, meta = NULL) {

  vc_type <- c(`metadata` = ".mt", `rawdata` = ".rw", `modeldata` = ".ml")
  vc_type <- vc_type[vc_type %in% type]

  if (is.null(meta)){
    tb <- select(df, -c(ends_with(type)))
    ls_tb <- purrr::map(vc_type, ~select(df, ends_with(".nm") | ends_with(.x)))
    ls_tb[[length(vc_type) + 1]] <- (tb)
  } else {
    ls_tb <- list2(metadata = meta, df)
  }

  purrr::reduce2(rev(ls_tb), rev(names(vc_type)), write_attr)
}

#-------------------------------------------------------------------------------
# Function for testing and validation (NOT EXPORTET)
#-------------------------------------------------------------------------------
# Validation function to check for empty files or files with empty columns
read_validator <- function(directory, types = c(".is_txt", ".chk_is", ".stat")){

# Argument class check
  stopifnot(is.character(directory))
# Check if directory contains files
    if (is.null(length(dir(directory)))){
      stop("`directory` does not contain any files", call. = FALSE)
    }
# Check if directory contains specified file types
    if (!ICdir_chk(directory, types)){
      stop("`directory` does not contain required filetypes:
           .is_txt, .chk_is, and .stat", call. = FALSE)
      }

# Extract txt files with count data blocks of each single point measurement
  ls_files <- purrr::map(types, ~read_names(directory, .x)) %>%
    set_names(nm = c("ion", "optic", "stat"))

  if (
    all.equal(names(ls_files[["ion"]]), names(ls_files[["optic"]])) &
    all.equal(names(ls_files[["ion"]]), names(ls_files[["stat"]]))
    )
    {
    ls_files[["optic"]] <- ls_files[["optic"]][names(ls_files[["optic"]]) %in%
                                             names(ls_files[["ion"]])]
    ls_files[["stat"]] <- ls_files[["stat"]][names(ls_files[["stat"]]) %in%
                                                 names(ls_files[["ion"]])]
    warning("Some metadata files have no matching data files and are omitted")
  }

# Length check of txt files
  if (any(missing_text(directory, ls_files[["ion"]]) == 0)) {

    good <- missing_text(directory, ls_files[["ion"]]) > 0
    ls_files[["ion"]] <- ls_files[["ion"]][good]
    warning("empty txt file removed")
  }

# Column content check of txt files
  if (any(missing_col(directory, ls_files[["ion"]]) == 0)) {

    good <- missing_col(directory, ls_files[["ion"]])  > 0
    ls_files[["ion"]] <- ls_files[["ion"]][good]
    warning("txt file contains empty columns")
  }
  return(ls_files)
}


# read file name function
read_names <- function(directory, ext) {

  list.files(directory, pattern = paste0(ext, "$")) %>%
# Set names for subsequent storage
    set_names(nm = sub(pattern = "(.*)\\..*$", replacement = "\\1", .)) %>%
# Remove transect files
    purrr::discard(str_detect(., paste0("transect", ext, "$")))
}




# Function for obtaining xyz coordinates on analytical substrate
str_loc <- function(loc) {

  loc %>%
    str_split("=+", simplify = TRUE) %>%
    str_subset("[:digit:]") %>%
    sapply(parse_number) %>%
    set_names(nm = c("x.mt", "y.mt", "z.mt"))
}


# Function to recreate count blocks
fun_bl<- function(x, y) {

  seq <- rep(1: unique(x), each = unique(y))
  n <- row_number()
  seq[n]

}

# Function for PHD data reading
PHD_fun <- function(directory, a, b, c) {

  readr::read_table2(
    paste0(directory, "/", a),
    col_names = c("num.mt", "mean_PHD.mt", "SD_PHD.mt", "EMHV.mt"),
    col_types = "-cddd",
    na = c(mapply(strrep,"X", 1:10, USE.NAMES = FALSE), "1.#R"),
    skip = b[1] - 1,
    n_max = c
    ) %>%
    mutate(num.mt = parse_number(.data$num.mt))
}


# Function for mass spec data reading
ion_fun <- function(directory, a, b, c) {

  readr::read_table(
    paste0(directory, "/", a),
    skip = b,
    n_max = c,
    col_names = c("num.mt", "species.nm", "mass.mt", "det.mt", "tc.mt",
                  "bfield.mt", "rad.mt"
                  ),
    col_types = "icdcddd---"
    )
}


# Function for optics reading
meas_fun <- function(directory, a , b) {

  NA_aliases <- c("N/A", "none", "None") %>%
    set_names(rep(NA_character_, length(.)), nm = .)

  tb_meas <- read_table(
    paste0(directory, "/", a),
    col_names = "var",
    col_types = "c",
    n_max = b,
    skip_empty_rows = FALSE
    ) %>%
    drop_na()

  name <- str_trim(str_split(pull(tb_meas, "var")[1],"\\:")[[1]][2])
  date <- pull(tb_meas, "var")[2] %>% str_trim()
  loc <- pull(tb_meas, "var")[3]  %>% str_trim()

  tb_meas <- tidyr::separate_rows(
    tb_meas[-c(1,3), 1],
    .data$var,
    sep = "(/(?=[[:blank:]])) | ="
    ) %>%
    tidyr::separate(
      .data$var,
      into = c("var", "value"),
      sep =":(?!\\\\)",
      extra = "merge"
    ) %>%
    mutate(across(everything(), str_trim)) %>%
    distinct(.data$var, .keep_all = TRUE) %>%
    mutate(
# Find missing meta
      value = recode(.data$value, !!! NA_aliases),
 # Remove units behind numeric
      value = str_replace(
        .data$value,
        "(?<=[:digit:]|[:blank:])(pA|um|%)|Det1=",
        ""
        )
      ) %>%
    tidyr::pivot_wider(
      names_from = .data$var,
      values_from = .data$value
      ) %>%
    # Separate extraction of date, location and name
    mutate(
      sample.nm = name,
      date.mt = as.POSIXct(date, format = c("%d.%m.%y  %H:%M")),
      !!!str_loc(loc)
      ) %>%
    mutate(across(everything(), str_trim))

}


# Row scanner determine number of rows
row_scanner <- function(directory, ls, str){

  lapply(
    purrr::map(
      ls,
      ~read_lines(paste0(directory, "/", .), n_max = Inf)
      ),
  str_which,
  str
  )

}


# File validator. Empty text files
missing_text <- function(directory, files){
  purrr::map_dbl(
    files,
    ~{length(read_lines(paste0(directory, "/", .), n_max = 2))}
    )
}


# File validator. Empty columns
missing_col <- function(directory, files){
  purrr::map_dbl(
    files,
    ~{nrow(
      read_tsv(
        paste0(directory, "/", .),
        comment = "B",
        skip = 1,
        col_names = c("t", "N"),
        col_types = "-cc",
        n_max = 2
        ) %>%
        filter(t != "X", N  != "Y"))
      }
    )
}


# Check analyses length consistency (IC data vs metadata)
compare_length <- function(df) {

  df_old <- mutate(df, n.rw = as.integer(n.rw))
  df_new <- add_count(df, file.nm, species.nm, name = "n.rw")
  waldo::compare(df_old, df_new)

}


write_attr <- function(df1, df2, nm) {
  attr(df1, nm) <- df2
  return(df1)
}
