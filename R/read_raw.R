#' Read raw ion count data
#'
#' \code{read_IC()} is designed to obtain the numerical data associated with ion
#' counts.
#' \code{read_meta()} can be used to specifically retrieve the metadate
#' associated with ion count data analysis, thereby loading specifications
#' related to the optics, the primary and secondary ion beams, and the mass
#' spectrometer.
#'
#' Ion count data consists of time-incremented integer values. These functions
#' are currently only supported for data generated by a NanoSIMS50L. Raw ion
#' count data and accompayning is extracted and collated into a single tibble
#' from text files with the extensions \emph{.is_txt} \emph{.chk_is} and
#' \emph{.stat},respectively. These files can be found in the directories
#' associated with the SIMS measurements.
#'
#' @param directory A path or connection to a directory containing raw ion count
#' data txt  files.
#'
#' @return A \code{\link[tibble:tibble]{tibble}} containing raw ion count data
#' and metadata
#' @export
#' @examples
#' # Use point_example() to access the examples bundled with this package
#'
#' read_IC(point_example("2018-01-19-GLENDON"))
read_IC <- function(directory, meta = TRUE, hide = TRUE){


  ls_IC <- read_names(directory, "is_txt")
  n_max <- Inf

# Collecting metadata (stat file)
  if (meta) {
    tb_meta <- read_meta(directory)
# Check validity of directory
    ls_IC <- read_validator(directory)[[1]]
    n_max <- group_by(tb_meta, file.nm) %>%
      summarise(n = sum(n.rw)) %>%
      pull(n) + length(unique(tb_meta$species.nm)) + 1
    #n_max <- Inf

    }

# Collecting measurement data
  tb_rw <- purrr::map2_dfr(
    ls_IC,
    n_max,
    ~read_tsv(
      paste0(directory, "/", .x),
      col_names = c("t.rw", "N.rw"),
      col_types = "-cc",
      comment = "B",
      skip = 1,
# n-max is n times number of species
      n_max = .y
       ),
    .id = "file.nm"
    ) %>%
# Remove old column headers
    filter(.data$t.rw != "X", .data$N.rw  != "Y") %>%
# Coercion to numeric values
    mutate(
      t.rw = as.numeric(.data$t.rw),
      N.rw = as.numeric(.data$N.rw)
      )


  if (meta) {
    vc_species <- set_names(
      unique(tb_meta$species.nm),
      nm = 1:length(unique(tb_meta$species.nm))
      )
    tb_rw <- group_by(tb_rw, .data$file.nm) %>%
      mutate(
        species.nm = ntile(n = length(unique(tb_meta$species.nm))),
        species.nm = recode(species.nm, !!! vc_species)
        ) %>%
      ungroup()

    if (hide) {
      tb_rw <- left_join(
        tb_rw,
        select(tb_meta, !ends_with(c(".mt")), - num.nm),
        by = c("file.nm", "species.nm")
        )
      tb_meta <- select(tb_meta, - c(num.nm, n.rw))
      attr(tb_rw,"metadata") <- tb_meta
      } else {
      tb_rw <- left_join(tb_rw, tb_meta, by = c("file.nm", "species.nm"))
      }


# Compare length consistency to gauge failures in measurement
    if (length(compare_length(tb_rw)) > 0) {
      warning("Inconsistency in the length of one ore more analyses.
              Use the function `compare_length()` to compare IC and meta data.")
    }
    return(tb_rw)

  }

  return(tb_rw)
}

#' @rdname read_IC
#'
#' @export
read_meta <- function(directory){

# Check validity of directory
  ls_files <- read_validator(directory)

#-------------------------------------------------------------------------------
# PHD
#-------------------------------------------------------------------------------
# Number of PHD measurements
  PHD_n <- row_scanner(directory, ls_files[["optic"]], "PHDc(?=\\(Mass)")

# List of function arguments for PHD
  ls_PHD <- lst(
    a = ls_files[["optic"]],
    b = PHD_n,
    c = lapply(.data$b, length)
    )

# Apply PHD reading function to list of arguments
  tb_PHD <- purrr::pmap_dfr(
    ls_PHD,
    PHD_fun,
    directory = directory,
    .id = "file.nm"
    )

#-------------------------------------------------------------------------------
# Ions and MS setup metadata
#-------------------------------------------------------------------------------
# Minimum of metadata rows
   min_n <- row_scanner(directory, ls_files[["stat"]], "#") %>%
    purrr::map_dbl(., 1)

# Maximum of metadata rows
  max_n <- row_scanner(directory, ls_files[["stat"]], "--") %>%
    purrr::map_dbl(., 1)

# List of function arguments for metadat function
  ls_ion <- lst(a = ls_files[["stat"]], b =  min_n  , c = (max_n - 3) - .data$b)

# Apply PHD reading function to list of arguments
  tb_ion <- purrr::pmap_dfr(
    ls_ion,
    ion_fun,
    directory = directory,
    .id = "file.nm"
    )

#-------------------------------------------------------------------------------
# Primary and secondary ion beam metadata
#-------------------------------------------------------------------------------
  tb_meas <- purrr::map2_dfr(
    ls_files[["optic"]],
    min_n - 2,
    meas_fun,
    directory = directory,
    .id = "file.nm"
    )

# Cameca parameters
   vc_params <- set_names(point::cam_params$cam, nm = point::cam_params$point)

# Select variables present
   vc_params <- vc_params[vc_params  %in% colnames(tb_meas)]
# Add required variables
   vc_params <- purrr::prepend(vc_params, c(file.nm = "file.nm"))

# Select variables
   tb_meas <- select(tb_meas , !!! vc_params) %>%
     mutate(
       across(contains(".mt"), parse_guess),
# Add measurement number
       n.rw = .data$`bl_num.mt` * .data$`meas_bl.mt`,
# Add electron detector type (EM or FC)
      det_type.mt = if_else("FC_start.mt" %in% colnames(.), "FC", "EM")
      )

# Combine PHD, MS and beam metadata (make list columns of metadata)
  purrr::reduce2(
      lst(tb_ion, tb_meas, tb_PHD),
      lst(by = c("file.nm"), by = c("file.nm", "num.nm")),
      left_join
      ) #%>%
    # nest(meta = ends_with(".mt"))

  }

#' Get path to point example
#'
#' This function comes from the package `readr`, and has been modified to access
#' the bundled datatsets in directory `inst/extdata` of `point`. This
#' function make them easy to access. This function is modified from
#' \code{\link[readr:readr_example]{readr_example}} of the package
#' \code{\link[readr]{readr}}.
#'
#' @param path Name of file. If `NULL`, the example files will be listed.
#' @export
#' @examples
#' point_example()
#' point_example("2018-01-19-GLENDON")
point_example <- function(path = NULL) {
  if (is.null(path)) {
    dir(system.file("extdata", package = "point"))
  } else {
    system.file("extdata", path, package = "point", mustWork = TRUE)
  }
}


#' Check if directory is suitable for point
#'
#' This function checks whether the necessary files for the `point` read
#' functions are included in the directory.
#'
#' @param directory A path or connection to a directory containing raw ion count
#' data files.
#' @param types Regular expression for the required file extensions. Default
#' searches for files ending with .is_txt, .chk_is, and .stat
#'
#' @return A logical indicating whether the directory is suitable for `point`
#' @export
#' @examples
#' ICdir_chk(point_example("2018-01-19-GLENDON"))
ICdir_chk <-function(directory, types = c(".is_txt", ".chk_is", ".stat")){

  purrr::map_lgl(paste0(types, "$"), ~any(str_detect(dir(directory), .x))) %>%
    all()
}


#-------------------------------------------------------------------------------
# Function for testing and validation (NOT EXPORTET)
#-------------------------------------------------------------------------------
# Validation function to check for empty files or files with empty columns
read_validator <- function(directory, types = c(".is_txt", ".chk_is", ".stat")){

# Argument class check
  stopifnot(is.character(directory))
# Check if directory contains files
    if (is.null(length(dir(directory)))){
      stop("`directory` does not contain any files", call. = FALSE)
    }
# Check if directory contains specified file types
    if (!ICdir_chk(directory, types)){
      stop("`directory` does not contain required filetypes:
           .is_txt, .chk_is, and .stat", call. = FALSE)
      }

# Extract txt files with count data blocks of each single point measurement
  ls_files <- purrr::map(types, ~read_names(directory, .x)) %>%
    set_names(nm = c("ion", "optic", "stat"))

  if (
    all.equal(names(ls_files[["ion"]]), names(ls_files[["optic"]])) &
    all.equal(names(ls_files[["ion"]]), names(ls_files[["stat"]]))
    )
    {
    ls_files[["optic"]] <- ls_files[["optic"]][names(ls_files[["optic"]]) %in%
                                             names(ls_files[["ion"]])]
    ls_files[["stat"]] <- ls_files[["stat"]][names(ls_files[["stat"]]) %in%
                                                 names(ls_files[["ion"]])]
    warning("Some metadata files have no matching data files and are omitted")
  }

# Length check of txt files
  if (any(missing_text(directory, ls_files[["ion"]]) == 0)) {

    good <- missing_text(directory, ls_files[["ion"]]) > 0
    ls_files[["ion"]] <- ls_files[["ion"]][good]
    warning("empty txt file removed")
  }

# Column content check of txt files
  if (any(missing_col(directory, ls_files[["ion"]]) == 0)) {

    good <- missing_col(directory, ls_files[["ion"]])  > 0
    ls_files[["ion"]] <- ls_files[["ion"]][good]
    warning("txt file contains empty columns")
  }
  return(ls_files)
}


# read file name function
read_names <- function(directory, ext) {

  list.files(directory, pattern = paste0(ext, "$")) %>%
# Set names for subsequent storage
    set_names(nm = sub(pattern = "(.*)\\..*$", replacement = "\\1", .)) %>%
# Remove transect files
    purrr::discard(str_detect(., paste0("transect", ext, "$")))
}


# Function for building IDs
ID_builder <- function(df, species, ...){

  species <- enquo(species)
  gr_by <- enquos(...)

  group_by(df, !!! gr_by, !! species) %>%
  mutate(ID = row_number()) %>%
  ungroup() %>%
  tidyr::unite(col = "ID", !!! gr_by, .data$ID, sep = "/", remove = FALSE)
}


# Function for obtaining xyz coordinates on analytical subsrtate
str_loc <- function(loc) {

  loc %>%
    str_split("=+", simplify = TRUE) %>%
    str_subset("[:digit:]") %>%
    sapply(parse_number) %>%
    set_names(nm = c("x", "y", "z"))
}


# Function to recreate count blocks
fun_bl<- function(x, y) {

  seq <- rep(1: unique(x), each = unique(y))
  n <- row_number()
  seq[n]

}

# Function for PHD reading
PHD_fun <- function(directory, a, b, c) {

  readr::read_table2(
    paste0(directory, "/", a),
    col_names = c("num.nm", "mean_PHD.mt", "SD_PHD.mt", "EMHV.mt"),
    col_types = "-cddd",
    na = c(mapply(strrep,"X", 1:10, USE.NAMES = FALSE), "1.#R"),
    skip = b[1] - 1,
    n_max = c
    ) %>%
    mutate(num.nm = parse_number(.data$num.nm))
}

# Function for metadata reading
ion_fun <- function(directory, a, b, c) {

  readr::read_table(
    paste0(directory, "/", a),
    skip = b,
    n_max = c,
    col_names = c("num.nm", "species.nm", "mass.mt", "det.mt", "tc.mt",
                  "bfield.mt", "rad.mt"
                  ),
    col_types = "icdcddd---"
    )
}

# function for machine stats
meas_fun <- function(directory, a , b) {

  NA_aliases <- c("N/A", "none", "None") %>%
    set_names(rep(NA_character_, length(.)), nm = .)

  tb_meas <- read_table(
    paste0(directory, "/", a),
    skip = 1,
    col_names = "var",
    col_types = "c",
    n_max = b,
    skip_empty_rows = FALSE
    ) %>%
    drop_na()

  date <- pull(tb_meas, "var")[1] %>% str_trim()
  loc <- pull(tb_meas, "var")[2]  %>% str_trim()

  tb_meas <- tidyr::separate_rows(
    tb_meas[-c(1,2), 1],
    .data$var,
    sep = "(/(?=[[:blank:]])) | ="
    ) %>%
    tidyr::separate(
      .data$var,
      into = c("var", "value"),
      sep =":(?!\\\\)",
      extra = "merge"
    ) %>%
    mutate(across(everything(), str_trim)) %>%
    distinct(.data$var, .keep_all = TRUE) %>%
    mutate(
# Find missing meta
      value = recode(.data$value, !!! NA_aliases),
 # Remove units behind numeric
      value = str_replace(
        .data$value,
        "(?<=[:digit:]|[:blank:])(pA|um|%)|Det1=",
        ""
        )
      ) %>%
    tidyr::pivot_wider(
      names_from = .data$var,
      values_from = .data$value
      ) %>%
    # Separate extraction of date
    mutate(
      date = as.POSIXct(date, format = c("%d.%m.%y  %H:%M")),
      !!!str_loc(loc)
      ) %>%
    mutate(across(everything(), str_trim))

}

# row scanner
row_scanner <- function(directory, ls, str){

  lapply(
    purrr::map(
      ls,
      ~read_lines(paste0(directory, "/", .), n_max = 50)
      ),
  str_which,
  str
  )

}

# empty text files
missing_text <- function(directory, files){
  purrr::map_dbl(
    files,
    ~{length(read_lines(paste0(directory, "/", .), n_max = 2))}
    )
}

# empyt column
missing_col <- function(directory, files){
  purrr::map_dbl(
    files,
    ~{nrow(
      read_tsv(
        paste0(directory, "/", .),
        comment = "B",
        skip = 1,
        col_names = c("t", "N"),
        col_types = "-cc",
        n_max = 2
        ) %>%
        filter(t != "X", N  != "Y"))
      }
    )
}

# check analyses length consistency
compare_length <- function(df) {

  df_old <- mutate(df, n.rw = as.integer(n.rw))
  df_new <- add_count(df, file.nm, species.nm, name = "n.rw")
  waldo::compare(df_old, df_new)

}


