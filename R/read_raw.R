#' Read raw ion count data
#'
#' \code{read_IC()} is designed to obtain the numerical data associated with ion
#' counts.
#' \code{read_meta()} can be used to specifically retrieve the metadate
#' associated with ion count data analysis, thereby loading specifications
#' related to the optics, the primary and secondary ion beams, and the mass
#' spectrometer.
#'
#' Ion count data consists of time-incremented integer values. These functions
#' are currently only supported for data generated by a NanoSIMS50L. Raw ion
#' count data and accompayning is extracted and collated into a single tibble
#' from text files with the extensions \emph{.is_txt} \emph{.chk_is} and
#' \emph{.stat},respectively. These files can be found in the directories
#' associated with the SIMS measurements.
#'
#' @param directory A path or connection to a directory containing raw ion count
#' data txt  files.
#'
#' @return A \code{\link[tibble:tibble]{tibble}} containing raw ion count data
#' and metadata
#' @export
#' @examples
#' # Use point_example() to access the examples bundled with this package
#'
#' read_IC(point_example("2018-01-19-GLENDON"))
read_IC <- function(directory){

# Check validity of directory
  l.c <- read_validator(directory)[[1]]

# Collecting metadata (stat file)
  tb.meta <- read_meta(directory)

# Collecting measurement data and metadata
  tb.rw <- left_join(
# Raw count data of measerument
                     purrr::map_df(l.c,
                            ~read_tsv(paste0(directory, "/", .),
                                      col_names = c("t.rw", "N.rw"),
                                      col_types = "-cc",
                                      comment = "B",
                                      skip = 1,
# n-max is n times number of species
                                      n_max = with(tb.meta,
                                                   (unique(
                                                     n.rw[file.nm == .]) + 1
                                                    ) *
                                                     length(unique(species.nm)
                                                            )
                                                   )
                                     ),
                            .id = "file.nm"
                                   ) %>%
# Remove old column headers
                      filter(.data$t.rw != "X",
                             .data$N.rw  != "Y"
                             ) %>%
# Coercion to numeric values
                      mutate(t.rw = as.numeric(.data$t.rw),
                             N.rw = as.numeric(.data$N.rw)
                             ) %>%
                              group_by(.data$file.nm) %>%
                              mutate(num.mt =
                                       ntile(n =
                                              with(tb.meta,
                                                     length(unique(species.nm))
                                                   )
                                             )
                                     ) %>%
                              ungroup(),
                     tb.meta,
                     by = c("file.nm", "num.mt")
                     ) %>%
# Clear suffix from filename
    mutate(file.nm = str_sub(.data$file.nm,
                              end = (str_length(.data$file.nm) - 7)
                             )
           ) %>%
# Add block number
        group_by(.data$file.nm, .data$species.nm) %>%
        mutate(bl.mt = fun_bl(.data$`bl_num.mt`, .data$`meas_bl.mt`)) %>%
        ungroup()

  return(tb.rw)
}

#' @rdname read_IC
#'
#' @export
read_meta <- function(directory){

# NA aliases
  NA_aliases <- c("N/A", "none", "None") %>%
    set_names(rep(NA_character_, length(.)), nm = .)

# Check validity of directory
  lst.files <- read_validator(directory)
  l.s <- lst.files[[2]]
  l.p <- lst.files[[3]]

#-------------------------------------------------------------------------------
# PHD
#-------------------------------------------------------------------------------
# Number of PHD measurements
  PHD_n <- lapply(purrr::map(l.p, ~read_lines(paste0(directory, "/", .),
                                              n_max = 50
                                              )
                            ),
                  str_which,
                  "PHDc(?=\\(Mass)"
                  )

# List of function arguments for PHD
  l.PHD <- lst(a = l.p,  b = PHD_n, c = lapply(.data$b, length))

# Function for PHD reading
  f.PHD <- function(a, b, c) {
    readr::read_table2(paste0(directory, "/", a),
                       col_names = c("num.mt",
                                     "mean_PHD",
                                     "SD_PHD",
                                     "EMHV"
                                     ),
                       col_types = "-cddd",
                       na = c(mapply(strrep,
                                     "X",
                                     1:10,
                                     USE.NAMES = FALSE),
                              "1.#R"
                             ),
                            skip = b[1] - 1,
                            n_max = c
                      )
    }

# Apply PHD reading function to list of arguments
  tb.PHD <- purrr::pmap_dfr(l.PHD, f.PHD, .id = "file.nm") %>%
    mutate(file.nm = str_sub(.data$file.nm,
                             end = (str_length(.data$file.nm) - 7)
                             )
           ) %>%
    mutate(num.mt = as.numeric(str_extract(.data$num.mt, "[:digit:]")
                               )
           )

#-------------------------------------------------------------------------------
# Ions and MS setup metadata
#-------------------------------------------------------------------------------
# Minimum of metadata rows
   min_n <- lapply(purrr::map(l.s, ~read_lines(paste0(directory, "/", .),
                                               n_max = 50
                                               )
                              ),
                   str_which,
                   "#"
                   ) %>%
    purrr::map(., 1) %>%
    purrr::flatten_dbl()

# Maximum of metadata rows
  max_n <- lapply(purrr::map(l.s, ~read_lines(paste0(directory, "/", .),
                                              n_max = 50
                                              )
                            ),
                  str_which,
                  "--") %>%
    purrr::map(., 1) %>%
    purrr::flatten_dbl()

# List of function arguments for metadat function
  l.ion <- lst(a = l.s, b =  min_n  , c = (max_n - 3) - .data$b)

# Function for metadata reading
  f.ion <- function(a, b, c) {
    read_table(paste0(directory, "/", a),
               skip = b,
               n_max = c,
               col_names = c("num.mt", "species.nm", "mass.mt", "det.mt",
                             "tc.mt", "bfield.mt", "rad.mt"),
               col_types = "icdcddd---"
              )
    }

# Apply PHD reading function to list of arguments
  tb.ion <- purrr::pmap_dfr(l.ion, f.ion, .id = "file.nm") %>%
    mutate(file.nm = str_sub(.data$file.nm,
                              end = (str_length(.data$file.nm) - 5)
                             )
           )
#-------------------------------------------------------------------------------
# Primary and secondary ion beam metadata
#-------------------------------------------------------------------------------
  tb.meas <- purrr::map2_df(l.s, min_n - 1 ,
                            ~(
                              read_lines(paste0(directory, "/", .x),
                                         n_max = .y) %>%
                                list() %>%
                                tibble::enframe(name = NULL, value = "meta")
                              ),
                            .id = "file.nm"
                            ) %>%
    mutate(file.nm = str_sub(.data$file.nm,
                             end = (str_length(.data$file.nm) - 5)
                             )
           )

  tb.meas <- tb.meas %>%
    mutate(meta= purrr::map(.data$meta, ~str_tidy(.x, NA_aliases))) %>%
    tidyr::unnest(cols = c(.data$meta)) %>%
    select_IC() %>%
    mutate_at(vars(contains(".mt")), as.double) %>%
# Add measurement number
    mutate(n.rw = .data$`bl_num.mt` * .data$`meas_bl.mt`) %>%
# Add electron detector type (EM or FC)
    mutate(det_type.mt = if_else("FC_start.mt" %in% colnames(.),
                                 "FC",
                                 "EM"
                                 )
          )

# Combine PHD, MS and beam metadata
  tb.meta <- lst(tb.ion, tb.meas, tb.PHD) %>%
    purrr::reduce2(. , lst(by = c("file.nm"),
                           by = c("file.nm", "num.mt")),
                   left_join) %>%
    mutate(file.nm = paste0(.data$file.nm, ".is_txt"))

  return(tb.meta)
  }

#' Get path to point example
#'
#' This function comes from the package `readr`, and has been modified to access
#' the bundled datatsets in directory `inst/extdata` of `point`. This
#' function make them easy to access. This function is modified from
#' \code{\link[readr:readr_example]{readr_example}} of the package
#' \code{\link[readr]{readr}}.
#'
#' @param path Name of file. If `NULL`, the example files will be listed.
#' @export
#' @examples
#' point_example()
#' point_example("2018-01-19-GLENDON")
point_example <- function(path = NULL) {
  if (is.null(path)) {
    dir(system.file("extdata", package = "point"))
  } else {
    system.file("extdata", path, package = "point", mustWork = TRUE)
  }
}

#-------------------------------------------------------------------------------
# Function for testing and validation (NOT EXPORTET)
#-------------------------------------------------------------------------------
# Validation function to check for empty files or files with empty columns
read_validator <- function(directory){

# Argument class check
  stopifnot(is.character(directory))
# Check if directory contains files
    if (is.null(length(dir(directory)))){
      stop("`directory` does not contain any files", call. = FALSE)
    }
# Check if directory contains specified file types
  l.types <- c(".is_txt$", ".chk_is$", ".stat$")
    if (!ICdir_chk(directory)){
      stop("`directory` does not contain required filetypes:
           .is_txt, .chk_is, and .stat", call. = FALSE)
      }

# Extract txt files with count data blocks of each single point measurement
  l.c <- dir(directory, pattern = ".is_txt$") %>%
# Set names for subsequent storage
    set_names()

# Extract stat files with diagnostics of the machine and statistics
  l.s <- dir(directory, pattern = ".stat$") %>%
# Set names for subsequent storage
    set_names() %>%
    # Remove transect files
    purrr::discard(., str_detect(., "transect.stat$"))

# Extract stat files with diagnostics for optics settings
  l.p <- dir(directory, pattern = ".chk_is$") %>%
    # Set names for subsequent storage
    set_names() %>%
    # Remove transect files
    purrr::discard(., str_detect(., "transect.chk_is$"))

# Remove metadata files with diagnostics of the machine and statistics
  l.c.edited <- map_chr(l.c, ~str_sub(.x, end = (str_length(.x) - 7)))
  l.s.edited <- map_chr(l.s, ~str_sub(.x, end = (str_length(.x) - 5)))
  l.p.edited <- map_chr(l.p, ~str_sub(.x, end = (str_length(.x) - 7)))

  if (sapply(lst(l.p, l.s, l.c), length) %>%
        tidyr::crossing() %>%
        nrow() > 1){
    l.s <- l.s[l.s.edited %in% l.c.edited]
    l.p <- l.p[l.p.edited %in% l.c.edited]
    warning("some metadata files have no matching data files and are omitted")
  }

# Length check of txt files
  if (
    any(
      purrr::map_dbl(l.c,
                     ~length(
                       read_lines(
                         paste0(directory, "/", .),
                         n_max = 2
                         )
                       )
                     ) == 0
      )
    ) {

    good <- purrr::map_dbl(l.c,
                           ~length(
                             read_lines(
                               paste0(directory, "/", .),
                               n_max = 2
                               )
                             )
                           ) > 0
    l.c <- l.c[good]
    warning("empty txt file removed")
  }

# Column content check of txt files
  if (
    any(
      purrr::map_dbl(l.c,
                     ~nrow(
                       read_tsv(
                         paste0(directory, "/", .),
                         comment = "B",
                         skip = 1,
                         col_names = c("t", "N"),
                         col_types = "-cc",
                         n_max = 2
                         ) %>%
                       filter(t != "X", N  != "Y"))) == 0
      )
    ){

    good <- purrr::map_dbl(l.c,
                           ~nrow(
                             read_tsv(
                               paste0(directory, "/", .),
                               comment = "B",
                               skip = 1,
                               col_names = c("X1", "t", "N"),
                               col_types = cols(X1 = col_skip(),
                               t = col_character(),
                               N = col_character()),
                               n_max = 2
                               ) %>%
                              filter(t != "X", N  != "Y")
                             )
                           ) > 0
    l.c <- l.c[good]
    warning("txt file contains empty columns")
  }
  return(lst(l.c, l.s, l.p))
}

# Function for building IDs
ID_builder <- function(df, species, ...){

  species <- enquo(species)
  gr_by <- enquos(...)

  group_by(df, !!! gr_by, !! species) %>%
  mutate(ID = row_number()) %>%
  ungroup() %>%
  tidyr::unite(col = "ID", !!! gr_by, .data$ID, sep = "/", remove = FALSE)
}


# Function for obtaining xyz coordinates on analytical subsrtate
str_loc <- function(str_raw) {
  str_raw %>%
    filter(.data$variable == "Stage Position") %>%
    str_split("=+") %>%
    purrr::as_vector() %>%
    str_subset("[:digit:]") %>%
    lapply(parse_number) %>%
    rlang::flatten_dbl()
}

# Function to create a tibble of string from readlines output of metadata
str_tibble <- function(str_raw) {
  str_raw %>%
# Create tibble from list
    tibble::enframe(name = NULL) %>%
# Remove empty rows
    filter(str_detect(.data$value, ".")) %>%
  # Remove date
    filter(!str_detect(.data$value, pattern  = "\t\t\t\t\t\t")) %>%
    tidyr::separate_rows(.data$value, sep = "(/(?=[:blank:])) | =") %>%
    tidyr::separate(.data$value,
                    into = c("variable", "value"),
                    sep =":(?!\\\\)",
                    extra = "merge"
                    ) %>%
    mutate_all(str_trim) %>%
    distinct(.data$variable, .keep_all = TRUE)
}

# Function for selecting possible meta variables
select_IC <- function(df) {

  meta.nm <-c ("Pre Sputtering Time (s)",
               "Block number",
               "Meas. per block",
               "Width Horizontal(V)",
               "Vertical(V)",
               "Primary Current before acq",
               "after acq",
               "Raster (um)",
               "Blanking",
               "FC Background before acq",
               "FC Background after acq",
               "Rejection(sigma)",
               "x",
               "y",
               "z"
               ) %>%
    # The to be used new names for the output
    set_names(., nm = c("presput.mt",
                        "bl_num.mt",
                        "meas_bl.mt",
                        "width_hor.mt",
                        "width_ver.mt",
                        "prim_cur_start.mt",
                        "prim_cur_after.mt",
                        "rast_com.mt",
                        "blank_rast.mt",
                        "FC_start.mt",
                        "FC_after.mt",
                        "rejection.mt",
                        "x.mt",
                        "y.mt",
                        "z.mt"
                        )
              )

  # Select variables present
  meta.nm <- meta.nm[meta.nm %in% colnames(df)]
  # Add required variables
  meta.nm <- purrr::prepend(meta.nm, c(file.nm = "file.nm",
                                       sample.nm = "sample.nm",
                                       date = "date"
                                       )
                            )
  # Select variables
  select(df, !!! meta.nm)
  }

# Function to make metadate readible
str_tidy <-  function(str_raw, NA_aliases) {

  str_raw %>%
    # Create tibble from list
    str_tibble() %>%
    # Convert NA aliases to NA
    mutate(value = recode(.data$value, !!!NA_aliases),
           # Remove units behind numerics
           value = str_replace(.data$value,
                               "(?<=[:digit:]|[:blank:])(pA|um|%)|Det1=",
                               ""
                               )
           ) %>%
    tidyr::pivot_wider(names_from = .data$variable,
                       values_from = .data$value) %>%
    # Separate extraction of date
    mutate(date = str_date(str_raw)) %>%
    rename(sample.nm = "CAMECA \\ ISOTOPES \\ Sample") %>%
    # Separate location of date
    mutate(x = str_loc(str_tibble(str_raw))[1],
           y = str_loc(str_tibble(str_raw))[2],
           z = str_loc(str_tibble(str_raw))[3]) %>%
    # Remove extra punct
    mutate(`Pre Sputtering Time (s)` =
             str_sub(.data$`Pre Sputtering Time (s)`, end = -2))

}


# Function for date extraction
str_date <- function(str_raw) {
  as.POSIXct(
    str_replace_all(
      str_raw[str_detect(str_raw, pattern  = "\t\t\t\t\t\t")],
      "\\t|\\n", ""
    ),
    format = c("%d.%m.%y  %H:%M")
  )
}

# Function to recreate count blocks
fun_bl<- function(x, y) {

  seq <- rep(1: unique(x), each = unique(y))
  n <- row_number()
  seq[n]

}

# Check if directory contains the correct filse necesarry for IC analysis
ICdir_chk <-function(directory, types = c(".is_txt$", ".chk_is$", ".stat$")){

  map_lgl(types, ~any(str_detect(dir(directory), .x))) %>%
      all()
}

