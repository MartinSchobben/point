#' Evaluate effect size of diagnostics
#'
#' \code{eval_diag} function for the evaluation of effect size of diagnostics
#'
#' @param ls_df A list of tibbles as generated by \code{diag_R}.
#' @param args A list of quosures pertaining to the variables required for a
#' call to stat_R. The function expr_R can be used to simplify setting this
#' argument.
#' @param df2 A dataframe with the ionization tend of the major ion in per
#' mille.
#' @param RSXt A variable constituting the relative standard deviation of the
#' major ion in the dataframe enetered for the argument \code{df2}.
#' @param n A variable indicating the number of observation in the list of
#' dataframes entered for the argument \code{ls_df}
#' @param ... Variables for grouping.
#' @param output A character string for output as summary statistics ("sum") and
#' statistics with the original data ("complete").
#'
#' @export
#' @examples
#' # evaluation of diagnostics
#' tb.eval <- eval_diag(
#'    ls.dia,
#'    args = expr_R_stat,
#'    flag = flag,
#'    iso_offset,
#'    simulation,
#'    trend,
#'    nest = TRUE,
#'    group = simulation
#'    )
eval_diag <- function(ls_df, args, flag, ..., nest = FALSE, group = NULL,
                      output = "sum", .tf = "ppt"
){

  gr_by <- enquos(..., .named = TRUE)
  flag <- enquo(flag)
  group <- enquo(group)

  # heavy isotope
  Xt1 <- quo_updt(args[["Xt"]], as_name(args[["ion1"]]))
  # light isotope
  Xt2 <- quo_updt(args[["Xt"]], as_name(args[["ion2"]]))

  # Chi squared light isotope
  Chi <- quo_updt(Xt2, x = "chi2")
  # Mean R
  M_R <- quo_updt(args[["Xt"]], x = "M_R")

  df <- reduce_diag(ls_df, "results", args)

  # Check number of levels of bad flag is more than 10
  df_n <-  count(df, .data$execution, !!!gr_by, !!flag)

  if (nrow(filter(df_n, !!flag == "bad" & n > 10)) == 0) {
  stop("Number of flagged outliers in all samples is too small for a reliable diagnostic. Execution has stopped.")
  }

  if (
    nrow(filter(df_n, flag == "bad" & n > 10)) <
      nrow(filter(df_n, flag == "bad"))
      ) {
    warning("Number of flagged outliers in some samples is too small for a reliable diagnostic. Execution proceeded with remaining samples.")
    # Otherwise filter dataset
    df <- filter(df_n, !!flag == "bad" & n < 10)  %>%
      select(.data$execution, !!!gr_by) %>%
      anti_join(df, ., by = c("execution", sapply(gr_by, as_name)))

  }

  # Check for ionization trend
  if (any(between(pull(df, !! Chi), 0.9, 1.1))) {
    warning("Linear ionization trend absent in some or all analyses; F value might be unreliable.")
  }


  # Re-center along flag variable
  df <- cstd_var(df, Xt1, quo(hat_Y), flag, !!! gr_by, execution)

  # Create zero (constrained) model flag and updated model
  df_lm <- tidyr::nest(df, data = -c(!!! gr_by,  .data$execution, !! M_R)) %>%
    mutate(
      lm_out =
        purrr::map(
          data,
          ~lm_fun(.x, .Xt1 = quo(std.var), .Xt2 = Xt2, .flag = flag)
          )
      ) %>%
    unnest_wider(lm_out)

  if (nest) {
    # Groups for nested data
    nest_gr <- gr_by[!sapply(gr_by, as_name) %in% as_name(group)]

    df_mlm <- df %>%
    # nest over nest groups
      tidyr::nest(data = -c(!!! nest_gr))

    df_mlm1 <- mutate(
      df_mlm,
      gls_out =
        purrr::map(
          data,
          purrr::possibly(gls_fun, NA),
          .Xt1 = Xt1,
          .Xt2 = Xt2,
          .tf = .tf,
          .group = group
          ),
      inter_out =
        purrr::map2(
          data,
          gls_out,
          purrr::possibly(mlm_fun1, NA),
          .Xt1 = Xt1,
          .Xt2 = Xt2,
          .tf = .tf,
          .group = group
          )
      ) %>%
        hoist(.col = gls_out, "ls_gls") %>%
        select(-c(gls_out, data)) %>%
        unnest_wider(ls_gls) %>%
        unnest_wider(inter_out)

    ls_mlm <- lst(df_lm, df_mlm1)

      # Check if longitudinal analyses can be performed
      if (length(unique(pull(df, .data$execution))) > 1) {

        df_mlm2 <- mutate(
          df_mlm,
          intra_out =
            purrr::map(
              data,
              purrr::possibly(mlm_fun2, NA),
              .Xt1 = Xt1,
              .Xt2 = Xt2,
              .tf = .tf,
              .group = group
              )
          ) %>%
          select(-data) %>%
          unnest_wider(intra_out)

        ls_mlm$df_mlm2 <- df_mlm2

      } else {
        warning("Longitudinal analyses cannnot be peformed.")
      }
    #
    # # prepare output
    df <- purrr::reduce(ls_mlm, left_join, by = sapply(nest_gr, as_name)) %>%
      eval_tidy(expr = output_lm(output))
    return(df)

  }

  # prepare output
  df <- df_lm %>%
    eval_tidy(expr = output_lm(output))
  return(df)
}


#-------------------------------------------------------------------------------
# Not exportet helper functions
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
# lm models
#-------------------------------------------------------------------------------

lm_fun <- function(.df, .Xt1, .Xt2, .flag) {

  ls_lm <- lst()

  # full R model
  lm_1 <- lm_form(.df, .Xt1, .Xt2, flag = .flag, type = "Rm")
  # zero R model
  lm_0 <- lm_form(.df, .Xt1, .Xt2, type = "Rm")
  # Effect size
  df_f <- tibble(effectsize::cohens_f(lm_1, model2 =  lm_0))
  ls_lm$f <- pull(df_f , Cohens_f_partial)
  ls_lm$f_cl <- pull(df_f , CI_low)
  ls_lm$f_ch <- pull(df_f , CI_high)
  # Join model hypothesis test
  df_aov <- broom::tidy(anova(lm_0 , lm_1))
  ls_lm$F_vl <- pull(df_aov, statistic)[2]
  ls_lm$p_F <- pull(df_aov, p.value)[2]

  return(ls_lm)

}


#-------------------------------------------------------------------------------
# gls models
#-------------------------------------------------------------------------------

gls_fun <- function(.df, .Xt1, .Xt2, .tf, .group) {

  # group-wise ratio of arithmetic mean
  M_R.gr <- quo_updt(expr(M_R), as_name(.group))

  # zero model
  gls_0 <- lm_form(.df, .Xt1, .Xt2, trans = .tf, type = "GLS")
  # log-log zero model
  log_gls_0 <- lm_form(.df, .Xt1, .Xt2, trans = "log", type = "GLS")

  ls_gls <- lst(
    # group-wise ratio of arithmetic mean (R)
    "M_R.{{.group}}" := coef_pull(gls_0, .df, .Xt2, .tf),
    # group-wise ratio of geometric mean (logR)
    GM_R = coef_pull(log_gls_0, .df, .Xt2, "log"),
    # comparison of geometric and arithmetic R
    dNorm = (GM_R / !!M_R.gr - 1) * 1000
    )

  return(lst(ls_gls, gls_0 = gls_0))
}

#-------------------------------------------------------------------------------
# mlm model inter R variability
#-------------------------------------------------------------------------------

mlm_fun1 <- function(.df, .gls, .Xt1, .Xt2, .tf, .group) {

  # zero model
  gls_0 <- purrr::pluck(.gls, "gls_0")
  # mlm inter model
  mlm_inter <- lm_form(
    .df,
    .Xt1,
    .Xt2,
    trans = .tf,
    vorce = "inter",
    nest = .group,
    type = "LME"
    )
  # log likelihood test
  df_aov <- anova(mlm_inter, gls_0)

  ls_inter <- lst(
    # model relative standard deviation of group and associated standard error
    RS_R_inter = mlm_RS(mlm_inter, .Xt2),
    RS_R_se_inter = mlm_RS(mlm_inter, .Xt2, output = "se"),
    # test statistic
    dAIC_inter = diff(pull(df_aov, `AIC`)),
    # p value
    p_inter = pull(df_aov, `p-value`)[2]
    )

  return(ls_inter)

}

#-------------------------------------------------------------------------------
# mlm model intra R variability
#-------------------------------------------------------------------------------

mlm_fun2 <- function(.df, .Xt1, .Xt2, .tf, .group) {

  # mlm intra model
  mlm_intra <- lm_form(.df, .Xt1, .Xt2, vorce = "intra", nest = .group,
                      type = "LME"
                      )

  # anova to check whether interaction with execution number is significant
  df_aov <- broom::tidy(car::Anova(mlm_intra, type = 3))

  ls_intra <- lst(
    # model relative standard deviation of group and associated standard error
    RS_R_intra = mlm_dR(mlm_intra, .Xt2),
    RS_R_se_intra = mlm_dR(mlm_intra, .Xt2, output = "se"),
    # p value
    p_intra = pull(df_aov, p.value)[2]
  )

  return(ls_intra)

}

#-------------------------------------------------------------------------------
# output function
#-------------------------------------------------------------------------------

output_lm <- function(.output) {

  switch(
    .output,
    sum = call2( "select", expr(.), expr(-data)),
    complete = call2("unnest", expr(.), cols = expr(data))
    )

}



coef_pull <- function(sum, data, arg, trans){

  cf <- unname(coef(sum))
  if (trans == "ppt") return(cf / 1000)
  if (trans == "log") return(trans_R(data, arg = arg, cf = cf))

}

# standardizing and re-center independent variable for fit to LM
#' @export
cstd_var <- function(df, Xt1, hat_Y, flag, ...){

  gr_by <- enquos(...)

  group_by(df, !!! gr_by, !! flag) %>%
    mutate(range = if_else(!!Xt1 >= !!hat_Y, "upper", "lower")) %>%
    group_by(!!! gr_by, !! flag, .data$range) %>%
    mutate(
      max.range = if_else(
        .data$range == "upper",
        max(!!Xt1 - !!hat_Y) ,
        min(!!Xt1 - !!hat_Y)
        ),
      min.range = if_else(
        .data$range == "upper",
        min(!!Xt1 - !!hat_Y) ,
        max(!!Xt1 - !!hat_Y)
        ),
      range.val = abs(.data$max.range - .data$min.range)
      ) %>%
    mutate(
      std.var =
        if_else(
          .data$range == "upper",
          abs((!! Xt1 - !! hat_Y) -.data$min.range) / .data$range.val,
          -abs((!! Xt1 - !! hat_Y) -.data$min.range) / .data$range.val
          ) * .data$range.val + !! hat_Y
      ) %>%
    ungroup() %>%
    select(-c(.data$max.range, .data$min.range, .data$range, .data$range.val))
}


# function to retrieve variable names of original or stats datasets
var_fun <- function(df, grps, args){

  vars <- colnames(df)
  # variables to be discarded
  pat_disc <- purrr::reduce(append(sapply(grps, as_name), "ID"),
                            str_c,
                            sep = "|"
  )
  #original col names
  var_names <- vars %>%
    set_names() %>%
    purrr::discard(~str_detect(.x,  pat_disc))

  # variables to be saved

  wide_vars <- purrr::map(c(as_name(args[["ion1"]]),
                            as_name(args[["ion2"]])
  ),
  ~paste(vars, .x, sep = ".")
  ) %>%
    purrr::reduce(append) %>%
    purrr::discard(~str_detect(.x, pat_disc))

  wide_vars.ion1 <- wide_vars[str_detect(wide_vars,
                                         as_name(args[["ion1"]])
  )
  ] %>%
    set_names(nm = var_names)
  wide_vars.ion2 <- wide_vars[str_detect(wide_vars,
                                         as_name(args[["ion2"]])
  )
  ] %>%
    set_names(nm = var_names)

  lst(original = var_names, ion1 = wide_vars.ion1, ion2 = wide_vars.ion2)
}

#' temporal trend of the fixed coefficient
#' @export
mlm_dR <- function(sum, arg, output = "value") {

  fix <- nlme::fixed.effects(sum) %>% unname()
  dR <- fix[2] / fix[1]
  if (output == "value") {return(dR * 1000)}
  if (output == "se"){
    fix.sd <- broom.mixed::tidy(sum) %>%
      select(std.error) %>%
      tidyr::drop_na() %>%
      mutate(sd = std.error  * sqrt(nobs(sum)),
             mean = dR)

    dR.se <- ((sqrt(((fix.sd$sd[1]/ fix.sd$mean[1]) ^ 2) + ((fix.sd$sd[2]/ fix.sd$mean[2]) ^ 2)) * dR) /  sqrt(nobs(sum)))
    return(dR.se  * 1000) # per mille
  }

}

#' Conditional coefficient back transformation
#' @export
trans_R <- function(data, arg, cf){

  M_log_pred <- mean(log(pull(data, !!arg)))
  GM_pred <- exp(M_log_pred)
  GM_resp <- exp(M_log_pred * cf)
  GM_resp / GM_pred

}

#' Relative standard deviation of the coefficient
#' @export
mlm_RS <- function(sum, arg, output = "value") {



  #if (trans) { arg <- paste0("I(",as_name(arg),"/1000)")} else { arg <- as_name(arg) }
  ran <- (nlme::VarCorr(sum))[,2] %>%
    tibble::enframe() %>%
    filter(str_detect(name, (as_name(arg))))

  ran <- as.numeric(tibble::deframe(ran[2,2]))
  fix <- nlme::fixed.effects(sum) %>% unname()

  RS <-  ran / fix

  if (output == "value") {return(RS * 1000)} # per mille

  if (output == "se"){
    # unequal distribution CI (95 %) converted to sd with deltamethod
    if (!is.null(nrow(sum$apVar))) {
      var_matrix <- sum$apVar
      par <- attr(var_matrix, "Pars")
      ran_sd <- msm::deltamethod(~ exp(x1)^2, par, var_matrix) * sqrt(nobs(sum))
    } else{
      ran_sd <- 0
    }

    # fixed effect CI (95 %) converted to sd
    fix_CI <- nlme::intervals(sum, which = "fixed")
    fix_sd <- fix_CI$fixed %>%
      tibble::as_tibble() %>%
      mutate(se = (upper - lower) / 3.92) %>%
      pull(se) * sqrt(nobs(sum))

    attr(fix_sd, "label") <- NULL

    # propagation when calculating isotope RS
    RS.se <- ((sqrt(((unique(ran_sd) / unique(ran)) ^ 2) + ((unique(fix_sd) / unique(fix)) ^ 2)) * RS) /  sqrt(nobs(sum))) #* 1000
    return(RS.se * 1000) # per mille
  }

}

